{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b236b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import WebDriverException,NoSuchElementException\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72be0a34",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cd195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875a6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Music videos',\n",
       " 'Geolocation software',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Alan Walker (music producer)',\n",
       " 'Baby Shark Dance',\n",
       " 'Baby Shark Dance',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Baby Shark Dance',\n",
       " 'Wired (website)',\n",
       " 'CNet',\n",
       " 'Criticism of YouTube',\n",
       " 'Censorship by YouTube',\n",
       " 'KSI vs. Logan Paul',\n",
       " 'List of most-viewed music videos in the first 24 hours']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bo = [] \n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"mw-redirect\"]'):\n",
    "    bo.append(i.get_attribute('title'))\n",
    "bo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3d2c5f",
   "metadata": {},
   "source": [
    "2. Scrape the details teamIndia’sinternationalfixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b386a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c42002",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "inter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453eef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,date,place,series,time = [],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "    date.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "    place.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "    series.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "    time.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18006130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Visakhapatnam</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match title         Series  \\\n",
       "0   1st ODI -         Mumbai   \n",
       "1   2nd ODI -  Visakhapatnam   \n",
       "2   3rd ODI -        Chennai   \n",
       "\n",
       "                                               Place         Date         Time  \n",
       "0                                  Wankhede Stadium,  17 MAR 2023  1:30 PM IST  \n",
       "1  Dr YS Rajasekhara Reddy ACA-VDCA Cricket Stadium,  19 MAR 2023  1:30 PM IST  \n",
       "2                            MA Chidambaram Stadium,  22 MAR 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCCI = pd.DataFrame({'Match title':series, 'Series':name, 'Place':place, 'Date':date, 'Time':time})\n",
    "BCCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "529ba840",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a07d1",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP ofIndia fromstatisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f595b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://www.statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc07977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eco = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "eco.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d5f4a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.statisticstimes.com/economy/india-statistics.php'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "new = ind.get_attribute('href')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a12f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18d6b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ind_gdp = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    gdp = ind_gdp.get_attribute('href')\n",
    "    driver.get(gdp)\n",
    "except WebDriverException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4c32132",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (575685858.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [35]\u001b[1;36m\u001b[0m\n\u001b[1;33m    for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]'):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    name,gsdp,share = [],[],[]\n",
    "      for i in driver.find_elements(By.XPATH,'//td[@class=\"name\"]'):\n",
    "        name.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data sorting_1\"]'):\n",
    "        gsdp.append(i.text)\n",
    "    for i in driver.find_elements(By.XPATH,'//td[@class=\"data\"]'):\n",
    "        share.append(i.text.split(','))\n",
    "except WebDriverException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed4753",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb2b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100a7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://github.com/trending')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d1bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo,des,lan = [],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]'):\n",
    "    repo.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]'):\n",
    "    des.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]'):\n",
    "    lan.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2312a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckaywrigley / chatbot-ui</td>\n",
       "      <td>A ChatGPT clone for running locally in your br...</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaiZhenbiao / ChuanhuChatGPT</td>\n",
       "      <td>GUI for ChatGPT API</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mayooear / gpt4-pdf-chatbot-langchain</td>\n",
       "      <td>GPT4 &amp; LangChain Chatbot for large PDF docs</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVIDIAGameWorks / Path-Tracing-SDK</td>\n",
       "      <td>Real-time path tracing library and sample</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GerevAI / gerev</td>\n",
       "      <td>🧠 ChatGPT search engine for your organization. 🔎</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keijiro / AICommand</td>\n",
       "      <td>ChatGPT integration with Unity Editor</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deep-diver / Alpaca-LoRA-Serve</td>\n",
       "      <td>Alpaca-LoRA as Chatbot service</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LianjiaTech / BELLE</td>\n",
       "      <td>BELLE: Bloom-Enhanced Large Language model Eng...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>typst / typst</td>\n",
       "      <td>A new markup-based typesetting system that is ...</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ryh04x / CEH-Exam-Questions</td>\n",
       "      <td>Planning To Take Certified Ethical Hacker (CEH...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>josStorer / chatGPTBox</td>\n",
       "      <td>Integrating ChatGPT into your browser deeply, ...</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nichtdax / awesome-totally-open-chatgpt</td>\n",
       "      <td>A list of totally open alternatives to ChatGPT</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fauxpilot / fauxpilot</td>\n",
       "      <td>FauxPilot - an open-source GitHub Copilot server</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>labmlai / annotated_deep_learning_paper_implem...</td>\n",
       "      <td>🧑‍🏫 59 Implementations/tutorials of deep learn...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TheR1D / shell_gpt</td>\n",
       "      <td>A command-line productivity tool powered by Ch...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Leizhenpeng / feishu-chatgpt</td>\n",
       "      <td>🎒飞书 ×（GPT-3.5 + DALL·E + Whisper）= 飞一般的工作体验 🚀 ...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>madawei2699 / myGPTReader</td>\n",
       "      <td>myGPTReader is a slack bot that can read any w...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hwchase17 / langchain</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pittcsc / Summer2023-Internships</td>\n",
       "      <td>Collection of Summer 2023 tech internships!</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>junegunn / fzf</td>\n",
       "      <td>🌸 A command-line fuzzy finder</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository title  \\\n",
       "0                           mckaywrigley / chatbot-ui   \n",
       "1                        GaiZhenbiao / ChuanhuChatGPT   \n",
       "2               mayooear / gpt4-pdf-chatbot-langchain   \n",
       "3                  NVIDIAGameWorks / Path-Tracing-SDK   \n",
       "4                                     GerevAI / gerev   \n",
       "5                                 keijiro / AICommand   \n",
       "6                      deep-diver / Alpaca-LoRA-Serve   \n",
       "7                                 LianjiaTech / BELLE   \n",
       "8                                       typst / typst   \n",
       "9                         ryh04x / CEH-Exam-Questions   \n",
       "10                             josStorer / chatGPTBox   \n",
       "11                        f / awesome-chatgpt-prompts   \n",
       "12            nichtdax / awesome-totally-open-chatgpt   \n",
       "13                              fauxpilot / fauxpilot   \n",
       "14  labmlai / annotated_deep_learning_paper_implem...   \n",
       "15                                 TheR1D / shell_gpt   \n",
       "16                       Leizhenpeng / feishu-chatgpt   \n",
       "17                          madawei2699 / myGPTReader   \n",
       "18                              hwchase17 / langchain   \n",
       "19                   pittcsc / Summer2023-Internships   \n",
       "20                                     junegunn / fzf   \n",
       "21                PlexPt / awesome-chatgpt-prompts-zh   \n",
       "\n",
       "                               Repository description     Language used  \n",
       "0   A ChatGPT clone for running locally in your br...        TypeScript  \n",
       "1                                 GUI for ChatGPT API            Python  \n",
       "2         GPT4 & LangChain Chatbot for large PDF docs        TypeScript  \n",
       "3           Real-time path tracing library and sample               C++  \n",
       "4    🧠 ChatGPT search engine for your organization. 🔎            Python  \n",
       "5               ChatGPT integration with Unity Editor                C#  \n",
       "6                      Alpaca-LoRA as Chatbot service            Python  \n",
       "7   BELLE: Bloom-Enhanced Large Language model Eng...            Python  \n",
       "8   A new markup-based typesetting system that is ...              Rust  \n",
       "9   Planning To Take Certified Ethical Hacker (CEH...        JavaScript  \n",
       "10  Integrating ChatGPT into your browser deeply, ...              HTML  \n",
       "11  This repo includes ChatGPT prompt curation to ...            Python  \n",
       "12     A list of totally open alternatives to ChatGPT  Jupyter Notebook  \n",
       "13   FauxPilot - an open-source GitHub Copilot server            Python  \n",
       "14  🧑‍🏫 59 Implementations/tutorials of deep learn...                Go  \n",
       "15  A command-line productivity tool powered by Ch...            Python  \n",
       "16  🎒飞书 ×（GPT-3.5 + DALL·E + Whisper）= 飞一般的工作体验 🚀 ...            Python  \n",
       "17  myGPTReader is a slack bot that can read any w...            Python  \n",
       "18  ⚡ Building applications with LLMs through comp...                Go  \n",
       "19        Collection of Summer 2023 tech internships!              HTML  \n",
       "20                      🌸 A command-line fuzzy finder        TypeScript  \n",
       "21                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。            Python  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git = pd.DataFrame({'Repository title':repo[0:22], 'Repository description':des[0:22], 'Language used':lan[0:22]})\n",
    "git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a84388",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57613b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https:/www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "353ca38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    top = driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "    top.click()\n",
    "except WebDriverException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25ee4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    driver.execute_script(\"window.scrollBy(0,200)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a3b84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,artist,lwr,pr,wob = [],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/h3'):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span'):\n",
    "    artist.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[1]/div[7]/span'):\n",
    "    lwr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[1]/div[8]/span'):\n",
    "    pr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div[1]/div[9]/span'):\n",
    "    wob.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a553d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet\"]'):\n",
    "    name.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"]'):\n",
    "    artist.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]'):\n",
    "    lwr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max\"]'):\n",
    "    pr.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max\"]'):\n",
    "    wob.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d012a85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 201, 201)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(artist),len(lwr),len(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82a6ceb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bill \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mArtist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43martist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLast Week Rank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mlwr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPeek Pos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m bill\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "bill = pd.DataFrame({'Name':name[0:100],'Artist':artist[0:100],'Last Week Rank':lwr[0:100],'Peek Pos':pr[0:100]})\n",
    "bill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ec980",
   "metadata": {},
   "source": [
    "Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e92aca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b09ed58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(40):\n",
    "    driver.execute_script(\"window.scrollBy(0,40)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "db293db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "book,author,volumes,publisher,genre = [],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/thead/tr/th[2]/div'):\n",
    "    book.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/thead/tr/th[3]/div'):\n",
    "    author.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/thead/tr/th[4]/div'):\n",
    "    volumes.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/thead/tr/th[4]/div'):\n",
    "    publisher.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/thead/tr/th[6]/div'):\n",
    "    genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cebb7413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>Title</td>\n",
       "      <td>Volume Sales</td>\n",
       "      <td>Volume Sales</td>\n",
       "      <td>Genre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Book Author       Volumes     Publisher  Genre\n",
       "0  Title  Title  Volume Sales  Volume Sales  Genre"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Guardian = pd.DataFrame({'Book':book, 'Author':book, 'Volumes':volumes, 'Publisher':publisher, 'Genre':genre})\n",
    "Guardian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b690480",
   "metadata": {},
   "source": [
    "Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95bab50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c545ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "name,year,gen,rt,rating,vote = [],[],[],[],[],[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]'):\n",
    "    na = i.text.split('(')[0]\n",
    "    name.append(na.split('.')[1])\n",
    "    year.append(i.text.split('(')[1].replace(')',' '))\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"genre\"]'):\n",
    "    gen.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"runtime\"]'):\n",
    "    rt.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]'):\n",
    "    rating.append(i.text.split('\\n')[0])\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//span[@name=\"nv\"]'):\n",
    "    vote.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2602d208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,140,943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–2024</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,225,349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,016,409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>299,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>258,192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name   Year Span                     Genre Run Time Ratings  \\\n",
       "0    Game of Thrones   2011–2019   Action, Adventure, Drama   57 min     9.2   \n",
       "1    Stranger Things   2016–2024     Drama, Fantasy, Horror   51 min     8.7   \n",
       "2   The Walking Dead   2010–2022    Drama, Horror, Thriller   44 min     8.1   \n",
       "3     13 Reasons Why   2017–2020   Drama, Mystery, Thriller   60 min     7.5   \n",
       "4            The 100   2014–2020     Drama, Mystery, Sci-Fi   43 min     7.6   \n",
       "\n",
       "       Votes  \n",
       "0  2,140,943  \n",
       "1  1,225,349  \n",
       "2  1,016,409  \n",
       "3    299,339  \n",
       "4    258,192  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.DataFrame({'Name':name, 'Year Span':year, 'Genre':gen, 'Run Time':rt, 'Ratings':rating, 'Votes':vote})\n",
    "series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc5e83",
   "metadata": {},
   "source": [
    "Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "adc6b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73cb842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "al = driver.find_element(By.XPATH,'//b')\n",
    "al.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "684e84f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [59]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m name \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//tr\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mhj\u001b[49m\u001b[38;5;241m.\u001b[39mappend(i\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hj' is not defined"
     ]
    }
   ],
   "source": [
    "name = []\n",
    "for i in driver.find_elements(By.XPATH,'//tr'):\n",
    "    hj.append(i.text.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22ff51",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e97e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"D:\\Data Science\\chromedriver_win32.zip\\chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7040317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.send_keys('Data science' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08dd01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2,desi2,com2,skill2,city2 = [],[],[],[],[]\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]'):\n",
    "    name2.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]'):\n",
    "    desi2.append(i.text)\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"vcard\"]'):\n",
    "    com2.append(i.text.split('\\n')[2])\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]'):\n",
    "    skill2.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f51ebe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,'//small[@class=\"ellipsis\"]'):\n",
    "    try:\n",
    "        city2.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        city2.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "89cecacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name        Designation  \\\n",
       "0              Aakash Harit         HR Manager   \n",
       "1      shravan Kumar Gaddam  Company Recruiter   \n",
       "2  MARSIAN Technologies LLP         Company HR   \n",
       "3              Anik Agrawal  Company Recruiter   \n",
       "4              subhas patel        Founder CEO   \n",
       "\n",
       "                                 Company  \\\n",
       "0                   Data Science Network   \n",
       "1          Shore Infotech India Pvt. Ltd   \n",
       "2               MARSIAN Technologies LLP   \n",
       "3  Enerlytics Software Solutions Pvt Ltd   \n",
       "4                        LibraryXProject   \n",
       "\n",
       "                                              Skills                      City  \n",
       "0  Classic ASP Developer, Internet Marketing Prof...                     Delhi  \n",
       "1  .Net, Java, Data Science, Linux Administration...  Hyderabad / Secunderabad  \n",
       "2  Data Science, Artificial Intelligence, Machine...                      Pune  \n",
       "3  Mean Stack, javascript, angularjs, mongodb, We...                 Ahmedabad  \n",
       "4  Hadoop, Spark, Digital Strategy, Data Architec...             UK - (london)  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nauk = pd.DataFrame({'Name':name2[0:48], 'Designation':desi2[0:48], 'Company':com2[0:48], 'Skills':skill2[0:48], 'City':city2[0:48]})\n",
    "nauk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d10e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
